{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./grid_reconstruction')\n",
    "\n",
    "import pygplates\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from reconstruct_atom_rasters import *\n",
    "from proximity_query import *\n",
    "import points_spatial_tree\n",
    "from sphere_tools import sampleOnSphere\n",
    "\n",
    "def reconstruct_grid(\n",
    "        time_of_existing_grid, \n",
    "        ascii_grid_file, \n",
    "        time_for_new_grid, \n",
    "        new_ascii_grid_file,\n",
    "        data_dir = '../data',\n",
    "        buffer_degrees = 15.):\n",
    "\n",
    "    rotation_model=pygplates.RotationModel(\n",
    "        data_dir+'/Rotations/Matthews_etal_GPC_2016_410-0Ma_GK07.rot' )\n",
    "    static_polygon_features = pygplates.FeatureCollection(\n",
    "        data_dir+'/ContinentalPolygons/Matthews_etal_GPC_2016_ContinentalPolygons.gpmlz' )\n",
    "\n",
    "    tmpX,tmpY = np.meshgrid(np.arange(-180.,181.,1.),np.arange(-90.,91.,1.)) \n",
    "    tmpX = tmpX.flatten()\n",
    "    tmpY = tmpY.flatten()\n",
    "\n",
    "    points,data_array = xyzfile_to_spatial_tree_of_points(ascii_grid_file)\n",
    "\n",
    "    spatial_tree_of_uniform_recon_points = points_spatial_tree.PointsSpatialTree(points)\n",
    "\n",
    "    ##############\n",
    "    # Continents\n",
    "    ##############\n",
    "\n",
    "    # reconstruct points within continent polygons from t_n+time_step to t_n\n",
    "    recon_point_lons, recon_point_lats, point_lons, point_lats = \\\n",
    "        reconstruct_raster_stage(\n",
    "            static_polygon_features, \n",
    "            rotation_model,\n",
    "            time_of_existing_grid,\n",
    "            time_for_new_grid,\n",
    "            points, \n",
    "            spatial_tree_of_uniform_recon_points)\n",
    "\n",
    "\n",
    "    # interpolate the values from the grid at t_n onto the unreconstructed points (where we \n",
    "    # already know the point locations at t_n+time_step)\n",
    "    d,l = sampleOnSphere(data_array[:,1],\n",
    "                         data_array[:,0],\n",
    "                         data_array[:,2],\n",
    "                         np.hstack(point_lats),\n",
    "                         np.hstack(point_lons),n=4)\n",
    "\n",
    "    interp_land_temp = data_array[:,2].ravel()[l]\n",
    "\n",
    "\n",
    "    ##########\n",
    "    # Oceans\n",
    "    ##########\n",
    "\n",
    "    # find points that are not within, and actually not close to (defined by some buffer distance) \n",
    "    # the continent polygons at t_n. This results in a set of points far from continents at t_n,\n",
    "    # but there may be some overlap with points within continents at t_n+time_step if the time step\n",
    "    # is large and/or the continents are moving quickly\n",
    "    pnp_test = run_grid_pnp(time_of_existing_grid,\n",
    "                            points,\n",
    "                            spatial_tree_of_uniform_recon_points,\n",
    "                            static_polygon_features, \n",
    "                            rotation_model, \n",
    "                            np.radians(buffer_degrees))\n",
    "\n",
    "    ocean_index = np.where(np.array(pnp_test)==0)\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    # Merged Land and Oceans\n",
    "    ##########################\n",
    "\n",
    "    merged_lons = np.hstack((np.hstack(recon_point_lons),data_array[ocean_index,0].flatten()))\n",
    "    merged_lats = np.hstack((np.hstack(recon_point_lats),data_array[ocean_index,1].flatten()))\n",
    "    merged_temp = np.hstack((interp_land_temp,data_array[ocean_index,2].flatten()))\n",
    "\n",
    "    merged_lons = ((merged_lons+180) % 360) - 180\n",
    "\n",
    "    d,l = sampleOnSphere(merged_lats,\n",
    "                         merged_lons,\n",
    "                         merged_temp,\n",
    "                         tmpY,\n",
    "                         tmpX,n=4)\n",
    "\n",
    "    interp_total_temp = merged_temp.ravel()[l]\n",
    "\n",
    "    # Write out an xyz file for each scalar type - each file contains (lon, lat, scalar).\n",
    "    write_xyz_file('tmp.xyz', zip(tmpX, tmpY, interp_total_temp))\n",
    "    write_xyz_file('buffer_tmp.xyz', zip(merged_lons, merged_lats, merged_temp))\n",
    "    write_xyz_file('buffer_land_tmp.xyz', zip(np.hstack(recon_point_lons), \n",
    "                                              np.hstack(recon_point_lats), \n",
    "                                              interp_land_temp))\n",
    "    write_xyz_file('buffer_ocean_tmp.xyz', zip(data_array[ocean_index,0].flatten(), \n",
    "                                               data_array[ocean_index,1].flatten(), \n",
    "                                               data_array[ocean_index,2].flatten()))\n",
    "\n",
    "    gmt_cmd = 'gmt'\n",
    "    # create a gmt grid that fills gaps using nearest-neighbour interpolation from python\n",
    "    # (but gaps are filled by interpolation from neighbouring continents as well as oceans)\n",
    "    os.system(gmt_cmd+' xyz2grd tmp.xyz -Gnearest_neighbour_fill_the_gap.nc -Rd -I%0.8f' % 1.)\n",
    "\n",
    "    # create a gmt grid that fills gaps using surface \n",
    "    # (but gaps are filled by interpolation from neighbouring continents as well as oceans)\n",
    "    os.system(gmt_cmd+' surface buffer_tmp.xyz -Ggmt_surface_fill_the_gap.nc -Rd -I%0.8f -T0.1' % 1.)\n",
    "\n",
    "    # create a seperate gmt grids for reconstructed land (with nan's in oceans) and oceans (using\n",
    "    # surface to fill gaps everwhere). Then blend together with continents taking precedence\n",
    "    # BUT: gaps within continent will look funny due to filling from oceans (e.g. within Himalayas)\n",
    "    os.system(gmt_cmd+' xyz2grd buffer_land_tmp.xyz -Gbuffer_land_tmp.nc -Rd -I%0.8f' % 1.)\n",
    "    os.system(gmt_cmd+' surface buffer_ocean_tmp.xyz -Gfill_ocean_tmp.nc -Rd -I%0.8f -T0.1' % 1.)\n",
    "    os.system(gmt_cmd+' grdblend buffer_land_tmp.nc fill_ocean_tmp.nc -Ggmt_grdblend_clobber.nc -Cf -Rd -I%0.8f' % 1.)\n",
    "    #os.system('/opt/gmt5/bin/gmt grdmath buffer_land_tmp.nc fill_ocean_tmp.nc OR = gmt_grdblend_clobber.nc')\n",
    "    os.system(gmt_cmd+' grdfilter %s -G%s -Fg%0.2f -D4 -Vl' % (\n",
    "        'gmt_surface_fill_the_gap.nc','gmt_surface_fill_the_gap_filter.nc',1000))\n",
    "    os.system(gmt_cmd+' grd2xyz gmt_surface_fill_the_gap_filter.nc > {0}'.format(new_ascii_grid_file) )\n",
    "    \n",
    "    #write_xyz_file(new_ascii_grid_file, zip(tmpX, tmpY, interp_total_temp))\n",
    "    data = np.loadtxt(new_ascii_grid_file)\n",
    "    new_data = []\n",
    "    \n",
    "    for x in range(0,361):\n",
    "        for y in range(90,-91,-1):\n",
    "            if x<=180:\n",
    "                new_data.append(data[361*(90-y)+x+180])\n",
    "            else:\n",
    "                l=list(data[361*(90-y)+x-180])\n",
    "                l[0]+=360\n",
    "                new_data.append(l)\n",
    "    \n",
    "    '''for line in new_data:\n",
    "        if line[2] > 40:\n",
    "            line[2] = 40\n",
    "        if line[2] < -40:\n",
    "            line[2] = -40\n",
    "    '''\n",
    "    os.system('rm '+ new_ascii_grid_file)       \n",
    "    write_xyz_file(new_ascii_grid_file, new_data)\n",
    "    print \"Reconstruction done!\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_temperature(time,times):\n",
    "    st = np.genfromtxt('./output/[{0}Ma_Golonka.xyz]_PlotData_Atm.xyz'.format(time),skip_header=1)\n",
    "    data = st[:,[0,1,6]]\n",
    "    for d in data:\n",
    "        d[1]=90-d[1]\n",
    "    ind = np.lexsort((-data[:,1],data[:,0]))    \n",
    "    print data[ind]\n",
    "    \n",
    "    with open('./output/[{0}Ma_Golonka.xyz]_PlotData_Atm_temperature.xyz'.format(time), 'w') as of:\n",
    "        for l in data[ind]:\n",
    "            of.write(' '.join(str(item) for item in l) + '\\n')\n",
    "\n",
    "    if t < (len(times)-1):\n",
    "        if not os.path.isdir('./output'.format(times[t+1])):\n",
    "            os.mkdir('./output'.format(times[t+1]))\n",
    "        reconstruct_grid(\n",
    "            time,\n",
    "           './output/[{0}Ma_Golonka.xyz]_PlotData_Atm_temperature.xyz'.format(time),\n",
    "            times[t+1],\n",
    "            './output/{0}Ma_SurfaceTemperature.xyz'.format(times[t+1]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_precipitation(time,times):\n",
    "    st = np.genfromtxt('./output/[{0}Ma_Golonka.xyz]_PlotData_Atm.xyz'.format(time),skip_header=1)\n",
    "    data = st[:,[0,1,8]]\n",
    "    for d in data:\n",
    "        d[1]=90-d[1]\n",
    "    ind = np.lexsort((-data[:,1],data[:,0]))    \n",
    "    print data[ind]\n",
    "    \n",
    "    with open('./output/[{0}Ma_Golonka.xyz]_PlotData_Atm_precipitation.xyz'.format(time), 'w') as of:\n",
    "        for l in data[ind]:\n",
    "            of.write(' '.join(str(item) for item in l) + '\\n')\n",
    "\n",
    "    if t < (len(times)-1):\n",
    "        if not os.path.isdir('./output'.format(times[t+1])):\n",
    "            os.mkdir('./output'.format(times[t+1]))\n",
    "        reconstruct_grid(\n",
    "            time,\n",
    "           './output/[{0}Ma_Golonka.xyz]_PlotData_Atm_precipitation.xyz'.format(time),\n",
    "            times[t+1],\n",
    "            './output/{0}Ma_SurfacePrecipitation.xyz'.format(times[t+1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pyatom import Model, Atmosphere, Hydrosphere\n",
    "\n",
    "model = Model()\n",
    "times=range(0,20,10)\n",
    "\n",
    "for t in range(len(times)):\n",
    "    time = times[t]\n",
    "    model.run_atm( time, './output/', './config_atm.xml' )\n",
    "    reconstruct_temperature(time,times)\n",
    "    reconstruct_precipitation(time,times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "\n",
    "def plot_xyz(topo, series, title, lats, lons, no_shift=False):\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    m = Basemap(llcrnrlon=-180,llcrnrlat=-90,urcrnrlon=180,urcrnrlat=90,projection='kav7', lon_0=0)\n",
    "\n",
    "    old_lons = lons\n",
    "    lons, topo = m.shiftdata(old_lons, datain = topo, lon_0=0)\n",
    "    lons, series = m.shiftdata(old_lons, datain = series, lon_0=0)\n",
    "\n",
    "    xi, yi = m(lons, lats)\n",
    "    \n",
    "    cs = m.scatter(xi, yi, marker='.', c=series, alpha=0.5, lw=0)#, vmin=-40, vmax=40)\n",
    "\n",
    "    # Add Grid Lines\n",
    "    m.drawparallels(np.arange(-90., 90., 10.), labels=[1,0,0,0], fontsize=10)\n",
    "    m.drawmeridians(np.arange(-180., 180., 45.), labels=[0,0,0,1], fontsize=10)\n",
    "\n",
    "    \n",
    "    if time == 0:\n",
    "        m.drawcoastlines()   \n",
    "        #m.barbs(xi[points], yi[points], adata[points, 4], adata[points, 3], pivot='middle', barbcolor='#333333')\n",
    "\n",
    "    else:  \n",
    "        #m.drawcoastlines()\n",
    "        con_topo = m.contour( xi.reshape((361,181)), yi.reshape((361,181)), topo.reshape((361,181)),\n",
    "                        colors ='k', linewidths= 0.3 )\n",
    "        \n",
    "    # Add Colorbar\n",
    "    cbar = m.colorbar(cs, location='bottom', pad=\"10%\")\n",
    "    # cbar.set_label(tmax_units)\n",
    "\n",
    "    # Add Title\n",
    "    plt.title(title)\n",
    "    #print plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "'''\n",
    "adata = np.loadtxt('./output-{0}/[{0}Ma_Golonka.xyz]_PlotData_Atm.xyz'.format(time), skiprows=1)\n",
    "atm_header = ['lats (deg)', 'lons (deg)', 'topography', 'v-velocity (m/s)', \n",
    "              'w-velocity (m/s)', 'velocity-mag (m/s)', 'temperature (Celcius)', \n",
    "              'water_vapour (g/kg)', 'precipitation (mm/d)', 'precipitable_water (mm)']\n",
    "\n",
    "alats = -(adata[:, 1] - 90.)\n",
    "alons = adata[:, 0]\n",
    "topo = adata[:, 2]\n",
    "plot_xyz(topo, adata[:, 6],  'temperature  ATOM atmosphere at Ma={0}'.format(time), alats, alons)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "st = np.genfromtxt('../data/SurfaceTemperature_NASA.xyz')\n",
    "adata = np.loadtxt('./output/[0Ma_Golonka.xyz]_PlotData_Atm.xyz', skiprows=1)\n",
    "topo = adata[:, 2]\n",
    "time=0\n",
    "plot_xyz(topo, series=st[:, 2], title='Surface Temperature_NASA (Celsius) at Ma=0', lons=adata[:, 0], lats=-(adata[:, 1] - 90.))\n",
    "plot_xyz(topo, series=adata[:, 6], title='Surface Temperature_NASA (Celsius) at Ma=0', lons=adata[:, 0], lats=-(adata[:, 1] - 90.))\n",
    "\n",
    "for t in range(10,150,10):\n",
    "    time=t\n",
    "    adata = np.loadtxt('./output/[{0}Ma_Golonka.xyz]_PlotData_Atm.xyz'.format(t), skiprows=1)\n",
    "    st = np.genfromtxt('./output/{0}Ma_SurfaceTemperature.xyz'.format(t))\n",
    "    alats = -(adata[:, 1] - 90.)\n",
    "    alons = adata[:, 0]\n",
    "    topo = adata[:, 2]\n",
    "    plot_xyz(topo, st[:, 2],  'Reconstructed temperature ATOM atmosphere at Ma={0}'.format(t), lons=st[:, 0], lats=st[:, 1])\n",
    "    plot_xyz(topo, adata[:, 6],  'Output temperature ATOM atmosphere at Ma={0}'.format(t), alats, alons)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pyatom import Model, Atmosphere, Hydrosphere\n",
    "\n",
    "model = Model()\n",
    "times=range(50,60,10)\n",
    "\n",
    "for t in range(len(times)):\n",
    "    time = times[t]\n",
    "    model.run_atm( time, './output/'.format(time), './config_atm.xml' )\n",
    "    #reconstruct_temperature(time,times)\n",
    "    adata = np.loadtxt('./output/[{0}Ma_Golonka.xyz]_PlotData_Atm.xyz'.format(time), skiprows=1)\n",
    "    alats = -(adata[:, 1] - 90.)\n",
    "    alons = adata[:, 0]\n",
    "    topo = adata[:, 2]\n",
    "    plot_xyz(topo, adata[:, 6],  'Output temperature ATOM atmosphere at Ma={0}'.format(time), alats, alons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for t in range(0,70,10):\n",
    "    adata = np.loadtxt('./output/[{0}Ma_Golonka.xyz]_PlotData_Atm.xyz'.format(t), skiprows=1)\n",
    "    data = adata[:,6]\n",
    "    data = data[~np.isnan(data)]\n",
    "    print np.nanmin(data), np.nanmax(data)\n",
    "    # the histogram of the data\n",
    "    n, bins, patches = plt.hist(data, 50, normed=1, facecolor='g', alpha=0.75)\n",
    "\n",
    "\n",
    "    #plt.xlabel('Smarts')\n",
    "    #plt.ylabel('Probability')\n",
    "    #plt.title('Histogram of IQ')\n",
    "    #plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n",
    "    #plt.axis([40, 160, 0, 0.03])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
